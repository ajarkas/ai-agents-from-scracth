{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **AI Agents from Scratch**\n",
    "\n",
    "\n",
    "*   **REQUIRED:** In Colab, connect to atleast T4 GPU\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "6n-_rqYkobr2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "kAB-0C36oakW"
   },
   "outputs": [],
   "source": [
    "#@title Install Dependencies\n",
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
    "    !pip install --no-deps unsloth\n",
    "\n",
    "import math, gc, torch, warnings\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import TextStreamer\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Loading the LLM\n",
    "\n",
    "#Recommened Models: Qwen3-8B (4bit) then Qwen3-14B (4bit)\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    \"unsloth/Qwen3-14B\",\n",
    "    max_seq_length = 5120, #adjust depending on RAM & Task\n",
    "    load_in_4bit   = True,\n",
    "    load_in_8bit   = False,\n",
    ")\n",
    "\n",
    "model.eval()\n"
   ],
   "metadata": {
    "collapsed": true,
    "id": "Gn9b82_6gQ72",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1d4d854b45624efca3caa2f4bbab8c3b",
      "e42dd823e83243f0ada21da070d314c7",
      "41aeaff782cc46edbff7ca3ac6768bd0",
      "719788b67de74cfc98ba09a07e198ef0",
      "4427dabc3e1442cc892e29cdd6b85a29",
      "e097e5db0af04bc6b1220312009e925c",
      "c0e58575d9a1466499189eb7201f5e7a",
      "7c3b1c87efb3417c91198c0f7f4c864f",
      "5e3505c29d6741bbb28c67972fd05a45",
      "b67aeca5a37c4b039b2512ceaffdbb39",
      "a1077bbcb339465b960f039ca4b735f2",
      "bf6a96f583264ad2a42760f22370dac7",
      "b04ad4db9e9e44b492065aa41bbbaf17",
      "439f342145a34d4394779eed57ab1596",
      "54d571c676b4467ca05f9eb7fc18a5e1",
      "9d84a9877f644bde8ceb0441f291d830",
      "2206fa16d3ae450e8c089c2f301168c0",
      "dedb3133385c40bd97d400edbbea56a6",
      "17c5dadae036437aa4b0a33a559ab3df",
      "2442ce256ed34e36b4fc18f874eb8b1d",
      "0cdff06f0ced47ac840e3e8a6bb0082c",
      "d307d405c5df441f94195b98ee488602",
      "0f143a4238f8459d9aaac2c883c28842",
      "cbdd770ca4014dbe8c0e3dade12bc156",
      "79123beaee72485eb27e6d94e6d84a9a",
      "dca89f4ecb5c48638543b58128517f16",
      "723b227c88bd4b69859bb57a4b636342",
      "24a775d769674fefa6bf4b5e51849363",
      "bd55820561b340898f84c789d2377255",
      "224554a33e0941259e7ec90eaabb9f10",
      "a6ec3fa3f4844473a632e9caa2c3c9fd",
      "bc147fc044ae4ff98ce5f0dcbc9a0cae",
      "22b1ba076f5f471cbffdc7a202a48ab6",
      "d05017fd2095499a8f921ed0e5f51995",
      "af1c1636ad7b46ad92bcd4562d5c8c79",
      "dd88731e74e34a8ebbdf34906d70a674",
      "c8c4379dfedd41b8aa3862e3b6583824",
      "db0cb008c1484fb39e40e1aff63fcaa7",
      "fc252fc1e5794db99870ea5796a57cb2",
      "5a3983091c11410683cfaa0627547762",
      "9de2c91e6c6e478dab1338087dd82b5e",
      "3edee9865ccc494a9ecb479c8d06aeb8",
      "abd3a8606dc74ac5bed2117cc6d768f1",
      "b5f6667cd9974c01bdb703eb549c4c59",
      "b7b8d6cfb0c54d6a9bbe2292f3e6be3b",
      "b4b68b0d433e4ad49a106af02909120e",
      "cd04dd8aee9e480081463432ea03245c",
      "88e5db0ab4c1447a982e69884f80848a",
      "801f586d94284b9f89b00cdbe58cc865",
      "3db3cb741aa545d1aca40180c78f8899",
      "86427131efab48e6905a5f1179132479",
      "5008380bfc5d459195bc02f14d16b366",
      "58b5ac012f994933af467376d76d2bcb",
      "c6f66ccd4eba456c84251d5527102821",
      "675b4b6d9df54b84aa32c02ba39ba374",
      "c97ff100ab40411baebf3a31b0498558",
      "dbc358eb94e6463cbb9f782789f003e4",
      "ae5d75a843214928b70999603c933a62",
      "cd4ee34fdeb24c57bdaa895e7fea17a4",
      "a060d28e2bed4784a050edd2cb01785a",
      "807b62fb2d784c59b3f7b53caa86b48e",
      "ee9201d84a9f4abe89cb913cf7bf8c6d",
      "8728b21d31c742fa930b9e5b675dd31e",
      "ac2faaf94d5f41bc9328ab9944fb7d76",
      "66bac1c3e7b04466a1a23f294e3bcf60",
      "bad8bcfbf2ad4d09bf2e5a192920cd4e",
      "81d502ce339d430a8fdb5bd2348e4ab9",
      "d1138b02fe3043f1b279d77b528651db",
      "a909c13a266d477c8503d579c5309854",
      "8b9016939d9a4ed1a592159d002d23c7",
      "d604a59245ab468cbf371a9f66e374ae",
      "0bf0a9d2f1f242fbae16dcec921847d0",
      "921c7d95e0a34e9095d5a9843a43927e",
      "ae499de95c954919beea0a2e3bea2cc3",
      "629879d481b74da2907e7af34da2deb8",
      "0fa7da90486f429f9c45552f3bc66dfc",
      "86cd0ec9d90b43df8d27f407094e17c4",
      "9e285aec8a504c7e869100f5a0465bd8",
      "389a58336ca54a5dbf3e435e8f125b35",
      "6e9c391ef28843b1b114a431ccc84e47",
      "71ab712333fb4338836f9d0809412549",
      "1d0d805715d64560a0d8c9a074c87ecb",
      "4e36c77000df4c89b7c6e240fc78a8d9",
      "1d302c4aaa0d435783d4112e628a2e8d",
      "ab37a12ed6544ce8a94dc9fd812e0939",
      "007502de264d477a8d66ca97242d2fde",
      "34dd3e0e9f744118828742b69a875622",
      "b72c450e767d44daa2d6e10f5eec2f48",
      "c0790bf3e304416088ebf6d54a1b85f7",
      "b776818c3ea84ab88eae5a0f3fc4ba62",
      "0709b7082eb54e78b033baf11fd2f478",
      "aaece98b98b44649a9316ec16f946601",
      "7d56f90e35be4bb281f12d9c35ea5c4a",
      "8946bd67e00d41c4ba36bf753bee1d8c",
      "1766318e7e14495c863d8cbf263560fd",
      "80b3de0dbe0b41e99c37dc8cc9804909",
      "4a15b0264ec847abbf9369175eba62ac",
      "d17c36599bb544b29ad38924f15450b5",
      "16ff17bd37cd4cbe8441bd1286b5b1a8",
      "3fdcce4e12274786a2710e22d8eb52a1",
      "82825f5769a54d96bb7e095818b58ae6",
      "354aa737de094b97b03605ac872c29ed",
      "3ccfc4030745463c92674eec11d972de",
      "87765830e8d749d4b176fba687089066",
      "9e6d6ff080d5439ca61a8dd3512c42b7",
      "bed9eaa3c5ce4dd2a5360175fef56438",
      "29f1086555a74c96ac32667844b435f0",
      "bd71738b66f4430c9ac4d84469d86d15",
      "25c26eeb124f41bc9c42aabf9945c1cb",
      "a6d34c15880d46cd9f8a48aacad4e7e7",
      "cc7ccc4b96494dc6831208b4a1d85540",
      "65c4b628222a4a4aaeff139ea98ab999",
      "9521c6ec9189462ba80b0a93971fd574",
      "7a538f763c2842499bb3d5694e6f85a0",
      "c4fa245f5e56449a810106858fe496cd",
      "4126a74bab2842c7abe360ef4f0029b8",
      "630efe5cca994fadad767f3b96ee24ac",
      "2cef2fb5aa79450e9d7bc0c2b44f1297",
      "f5896415a602489e9373f06badbac130",
      "f8f20b13d5bc48bba22df226dd580016",
      "e3a88f56ca5a44a9abf8efb6b982c6cb",
      "1110f0e3f6404b6aa958713784a87f4e",
      "8ee16d3a5a0b405ab57236b09a1e2da6",
      "e8077333b6154777a26a929d9b053f22",
      "9d535a916b434cf7b405a20bc86c84d8",
      "23d3b0e5e9744361ba2b239dcaeca0e2",
      "5ed3ac6b97c44eeea7712b2d649dcbe3",
      "7f5cb2cb71ad424cb6c9a3461c657325",
      "60bd46f2732740dcb1e7c0a18a870512",
      "fdb3bf78e6374472ab41860c821816e8",
      "9796bc03ef544a02809310109b4ff2f3",
      "b4910f36b81241f2baf93da668f92e5d"
     ]
    },
    "outputId": "f4d9a645-67ee-4abf-d65b-ca23b16061dc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==((====))==  Unsloth 2025.8.6: Fast Qwen3 patching. Transformers: 4.55.1.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d4d854b45624efca3caa2f4bbab8c3b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf6a96f583264ad2a42760f22370dac7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.50G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f143a4238f8459d9aaac2c883c28842"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d05017fd2095499a8f921ed0e5f51995"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7b8d6cfb0c54d6a9bbe2292f3e6be3b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c97ff100ab40411baebf3a31b0498558"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81d502ce339d430a8fdb5bd2348e4ab9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e285aec8a504c7e869100f5a0465bd8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0790bf3e304416088ebf6d54a1b85f7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3fdcce4e12274786a2710e22d8eb52a1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc7ccc4b96494dc6831208b4a1d85540"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1110f0e3f6404b6aa958713784a87f4e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 4096, padding_idx=151654)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (3): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (4): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (5): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (6): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (7-33): 27 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (34): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (35): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Function to Generate LLM Response\n",
    "def generate_response(message, messages):\n",
    "  \"\"\"\n",
    "  Inputs: message <string> -> latest user message,\n",
    "          messages <List> -> chat history\n",
    "\n",
    "  Output: LLM response <string>\n",
    "\n",
    "  \"\"\"\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False,\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=5120, #adjust depending on RAM & Task\n",
    "            temperature=0.7,\n",
    "            top_p=0.8,\n",
    "            top_k=20,\n",
    "        )\n",
    "\n",
    "    gen_ids = output_ids[0, inputs[\"input_ids\"].shape[-1]:]\n",
    "    result_text = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
    "    print(str(result_text).replace(\"END_TASK\", \"\").strip())\n",
    "    messages.append({\"role\": \"assistant\", \"content\": result_text})\n",
    "    return result_text"
   ],
   "metadata": {
    "id": "YX5nrqGaQ2lk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Defining your custom tools\n",
    "!pip install -q yfinance #Yahoo Finance (Stock API)\n",
    "\n",
    "def get_current_date():\n",
    "  \"\"\"\n",
    "  Get the current date in the format 'YYYY-MM-DD'.\n",
    "\n",
    "  parameters: None\n",
    "  returns: string in the format 'YYYY-MM-DD'\n",
    "  \"\"\"\n",
    "  import datetime\n",
    "  return datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def get_stock_data(ticker_symbol: str, start_date: str, end_date: str):\n",
    "  \"\"\"\n",
    "  Get historical stock data for a given ticker symbol. Assuming all dates are valid. if not valid, will return None\n",
    "\n",
    "  Parameters:\n",
    "  - ticker_symbol (str): The ticker symbol of the stock.\n",
    "  - start_date (str): The start date in the format 'YYYY-MM-DD'.\n",
    "  - end_date (str): The end date in the format 'YYYY-MM-DD'.\n",
    "\n",
    "  Returns:\n",
    "  - string form of pandas.DataFrame\n",
    "  \"\"\"\n",
    "  import yfinance as yf\n",
    "  from datetime import datetime, timedelta\n",
    "  warnings.filterwarnings(\"ignore\", module=r\"yfinance\\..*\")\n",
    "\n",
    "  #pad time window as some dates are invalid trading days\n",
    "  start_date = datetime.strptime(start_date, '%Y-%m-%d') - timedelta(days=4)\n",
    "  end_date = datetime.strptime(end_date, '%Y-%m-%d') + timedelta(days=4)\n",
    "\n",
    "  with warnings.catch_warnings():\n",
    "      warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yfinance\")\n",
    "      data = yf.download(ticker_symbol, start=start_date, end=end_date,\n",
    "                        progress=False, auto_adjust=True)\n",
    "  if data.empty:\n",
    "    return \"Date used is not trading day, try ± 4 day around the start & end date\"\n",
    "  return str(data.Close.to_dict())\n",
    "\n",
    "def get_current_time():\n",
    "    \"\"\"\n",
    "    Returns current time in HH:MM:SS string format\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    return datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "\n",
    "def save_csv(data, directory=\"\", filename=\"output.csv\"):\n",
    "  \"\"\"\n",
    "  Save a pandas DataFrame to a CSV file in a specified directory.\n",
    "\n",
    "  Parameters:\n",
    "  data <dict>,\n",
    "  directory <string>,\n",
    "  filename <string>\n",
    "\n",
    "  Output: Success or Failure <string>\n",
    "\n",
    "  \"\"\"\n",
    "  import pandas as pd\n",
    "  import os\n",
    "\n",
    "  if directory != \"\" and not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "  try:\n",
    "    if isinstance(data, dict):\n",
    "      data = pd.DataFrame(data)\n",
    "    data.to_csv(os.path.join(directory, filename), index=False)\n",
    "    return \"Success\"\n",
    "  except:\n",
    "    return \"Failure\""
   ],
   "metadata": {
    "id": "gFiMQgOMpFDF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Assigning Toolset (To call on tools for later)\n",
    "tools = {\n",
    "          'get_current_date': get_current_date,\n",
    "          'get_stock_data': get_stock_data,\n",
    "          'save_csv': save_csv,\n",
    "          #'get_current_time': get_current_time,\n",
    "         }\n",
    "\n",
    "\n",
    "#Context of your tools' functionality, parameters, and outputs for LLM usage\n",
    "tool_docs = \"\\n\".join([f\"{i.__name__}: {i.__doc__}\" for i in tools.values()])\n",
    "print(tool_docs)"
   ],
   "metadata": {
    "id": "tXdMikUgp1ld",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d2709ec6-1ad5-4596-d720-be31b24d0c64"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "get_current_date: \n",
      "  Get the current date in the format 'YYYY-MM-DD'.\n",
      "\n",
      "  parameters: None\n",
      "  returns: string in the format 'YYYY-MM-DD'\n",
      "  \n",
      "get_stock_data: \n",
      "  Get historical stock data for a given ticker symbol. Assuming all dates are valid. if not valid, will return None\n",
      "\n",
      "  Parameters:\n",
      "  - ticker_symbol (str): The ticker symbol of the stock.\n",
      "  - start_date (str): The start date in the format 'YYYY-MM-DD'.\n",
      "  - end_date (str): The end date in the format 'YYYY-MM-DD'.\n",
      "\n",
      "  Returns:\n",
      "  - string form of pandas.DataFrame\n",
      "  \n",
      "save_csv: \n",
      "  Save a pandas DataFrame to a CSV file in a specified directory.\n",
      "\n",
      "  Parameters:\n",
      "  data <dict>,\n",
      "  directory <string>,\n",
      "  filename <string>\n",
      "\n",
      "  Output: Success or Failure <string>\n",
      "\n",
      "  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title System Prompt (Default prompt for LLM aka Instructions)\n",
    "\n",
    "system_prompt = f\"\"\"You're an AI assistant with access to these tools (python functions):\\n\n",
    "{tool_docs}\n",
    "\n",
    "Given a prompt from the user, assess calling these tools is needed and in which synchronous order.\n",
    "If not needed, you can do your own assesments and calculations. If tools are needed,\n",
    "then call one tool at a time according to order of operations. Only call one tool\n",
    "per response. After you receive that response, call the next necessary tool\n",
    "until you have completed and answered the user's question. In your final response, end it with \"END_TASK\".\n",
    "\n",
    "ANSWER THE USER DIRECTLY, CONCISELY, and FORTHRIGHTLY.\n",
    "\n",
    "Examples:\n",
    "- <tool>get_current_time</tool>\n",
    "- <tool>get_stock_data</tool> <args>{{'ticker_symbol': 'AAPL', 'start_date': '2024-01-01', 'end_date': '2024-01-31'}}</args>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(system_prompt)"
   ],
   "metadata": {
    "id": "T-wnFvMrrprO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bdc94097-89d7-40a1-ad14-bcc79da2d4c3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You're an AI assistant with access to these tools (python functions):\n",
      "\n",
      "get_current_date: \n",
      "  Get the current date in the format 'YYYY-MM-DD'.\n",
      "\n",
      "  parameters: None\n",
      "  returns: string in the format 'YYYY-MM-DD'\n",
      "  \n",
      "get_stock_data: \n",
      "  Get historical stock data for a given ticker symbol. Assuming all dates are valid. if not valid, will return None\n",
      "\n",
      "  Parameters:\n",
      "  - ticker_symbol (str): The ticker symbol of the stock.\n",
      "  - start_date (str): The start date in the format 'YYYY-MM-DD'.\n",
      "  - end_date (str): The end date in the format 'YYYY-MM-DD'.\n",
      "\n",
      "  Returns:\n",
      "  - string form of pandas.DataFrame\n",
      "  \n",
      "save_csv: \n",
      "  Save a pandas DataFrame to a CSV file in a specified directory.\n",
      "\n",
      "  Parameters:\n",
      "  data <dict>,\n",
      "  directory <string>,\n",
      "  filename <string>\n",
      "\n",
      "  Output: Success or Failure <string>\n",
      "\n",
      "  \n",
      "\n",
      "Given a prompt from the user, assess calling these tools is needed and in which synchronous order. \n",
      "If not needed, you can do your own assesments and calculations. If tools are needed,\n",
      "then call one tool at a time according to order of operations. Only call one tool\n",
      "per response. After you receive that response, call the next necessary tool\n",
      "until you have completed and answered the user's question. In your final response, end it with \"END_TASK\".\n",
      "\n",
      "ANSWER THE USER DIRECTLY, CONCISELY, and FORTHRIGHTLY.\n",
      "\n",
      "Examples:\n",
      "- <tool>get_current_time</tool>\n",
      "- <tool>get_stock_data</tool> <args>{'ticker_symbol': 'AAPL', 'start_date': '2024-01-01', 'end_date': '2024-01-31'}</args>\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Calling relevant Tool given LLM output string\n",
    "\n",
    "import re\n",
    "def call_tool(tool_blurb):\n",
    "  \"\"\"\n",
    "  Input: LLM output (string) with tool call (i.e §tool_name§)\n",
    "  Operation: Transforms the LLM output string to a tool call operation in python\n",
    "  Output: Result Tool call operation (i.e get_current_time -> 12:59:00 PM)\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  #Parse/Extract tool name and tool parameters\n",
    "  tool_name = re.findall(r'<tool>(.*?)</tool>', tool_blurb)[0] if '<tool>' in tool_blurb else None\n",
    "  tool_args = re.findall(r'<args>(.*?)</args>', tool_blurb)[0] if '<args>' in tool_blurb else None\n",
    "\n",
    "  if tool_name and tool_args:\n",
    "    return tools[tool_name](**eval(tool_args))\n",
    "  elif tool_name:\n",
    "    return tools[tool_name]()\n",
    "  else:\n",
    "    return \"No tool call found\"\n",
    "\n",
    "\n",
    "llm_output = \"<tool>get_current_date</tool>\" #sample output for demonstration purposes\n",
    "call_tool(llm_output)"
   ],
   "metadata": {
    "id": "XLN7WNgFwmbG",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "bc0d3ac2-d7c8-467a-88de-37ce3244d612"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2025-08-17'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title LLM Loop (User Prompt -> LLM Thinking, Tool Calling, ... -> Final Answer)\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "message = \"\"\"I purchased 234 stock shares of NVIDIA on 4/7/2025, I just sold all shares 5 days ago. How much did I make?\n",
    "\n",
    "Save that buy/sell information as orders.csv in current directory\n",
    "with columns date, ticker, price, quantity, action (buy/sell), total_value (price * quantity)\n",
    "\"\"\"\n",
    "\n",
    "#initializers\n",
    "resp = \"\"\n",
    "count = 0\n",
    "\n",
    "#Loops, calls tools when needed, stops when final answer is produced noted by tag 'END_TASK'\n",
    "while 'END_TASK' not in resp:\n",
    "  resp = generate_response(message, messages)\n",
    "\n",
    "  if '<tool>' in resp:\n",
    "    message = f\"Tool output: {call_tool(resp)}\"\n",
    "    count += 1\n",
    "  else:\n",
    "    message = \"\"\n",
    "\n",
    "  #If agent falls in endless loop, cease\n",
    "  count += 1\n",
    "  if count > 20:\n",
    "    \"Timed Out\"\n",
    "    break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu02j-xry2v6",
    "outputId": "422faf07-0b60-4d80-faf9-02e635cb50cb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<tool>get_current_date</tool>\n",
      "The current date is 2025-08-17. You sold all shares 5 days ago, which means the sale date was 2025-08-12. Let's retrieve the stock data for NVIDIA (ticker: NVDA) between 2025-08-12 and 2025-08-17 to calculate your profit. \n",
      "\n",
      "<tool>get_stock_data</tool> <args>{'ticker_symbol': 'NVDA', 'start_date': '2025-08-12', 'end_date': '2025-08-17'}</args>\n",
      "The stock data for NVIDIA (NVDA) between 2025-08-12 and 2025-08-17 has been retrieved. Now, let's calculate the profit based on the sale date (2025-08-12) and the purchase date (2025-04-07). \n",
      "\n",
      "<tool>get_stock_data</tool> <args>{'ticker_symbol': 'NVDA', 'start_date': '2025-04-07', 'end_date': '2025-04-07'}</args>\n",
      "The stock price on the purchase date (2025-04-07) was $97.63, and the stock price on the sale date (2025-08-12) was $183.16. \n",
      "\n",
      "Now, let's calculate the profit based on the purchase and sale prices and the quantity of shares (234). \n",
      "\n",
      "<tool>save_csv</tool> <args>{'data': {'date': ['2025-04-07', '2025-08-12'], 'ticker': ['NVDA', 'NVDA'], 'price': [97.63, 183.16], 'quantity': [234, 234], 'action': ['buy', 'sell'], 'total_value': [234 * 97.63, 234 * 183.16]}, 'directory': '.', 'filename': 'orders.csv'}</args>\n",
      "The buy and sell information has been successfully saved as `orders.csv` in the current directory. Based on the purchase price of $97.63 and the sale price of $183.16 for 234 shares, your profit is calculated as follows:\n",
      "\n",
      "- **Total Cost (Buy):** 234 * $97.63 = $22,865.42  \n",
      "- **Total Revenue (Sell):** 234 * $183.16 = $42,765.44  \n",
      "- **Profit:** $42,765.44 - $22,865.42 = **$19,900.02**\n",
      "\n",
      "You made a profit of **$19,900.02**.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    " #@title Output from AI Agent\n",
    "import pandas as pd\n",
    "pd.read_csv('orders.csv')"
   ],
   "metadata": {
    "id": "upiW3VZeT8y5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "outputId": "6ab2cb50-ce8f-47f9-f9bc-7ebfe49674f0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         date ticker   price  quantity action  total_value\n",
       "0  2025-04-07   NVDA   97.63       234    buy     22845.42\n",
       "1  2025-08-12   NVDA  183.16       234   sell     42859.44"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-cfd59594-1f46-4688-a79f-cb40b80a3089\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>action</th>\n",
       "      <th>total_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>97.63</td>\n",
       "      <td>234</td>\n",
       "      <td>buy</td>\n",
       "      <td>22845.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-12</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>183.16</td>\n",
       "      <td>234</td>\n",
       "      <td>sell</td>\n",
       "      <td>42859.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfd59594-1f46-4688-a79f-cb40b80a3089')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-cfd59594-1f46-4688-a79f-cb40b80a3089 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-cfd59594-1f46-4688-a79f-cb40b80a3089');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-1654d663-8fcc-46a0-986e-9c2661e0173a\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1654d663-8fcc-46a0-986e-9c2661e0173a')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-1654d663-8fcc-46a0-986e-9c2661e0173a button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2025-08-12\",\n          \"2025-04-07\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"NVDA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60.47884299488541,\n        \"min\": 97.63,\n        \"max\": 183.16,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          183.16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quantity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 234,\n        \"max\": 234,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          234\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"sell\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14152.04926080319,\n        \"min\": 22845.42,\n        \"max\": 42859.44,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          42859.44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 31
    }
   ]
  }
 ]
}
